{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from typing import Dict, Any \n", "import numpy as np\n", "import pandas as pd\n", "import os\n", "import pickle\n", "import matplotlib.pyplot as plt\n", "from scipy.stats import invgamma\n", "import logging"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from loader_qmap_pd import load_qmap_pd as qmap_pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logging.basicConfig(level=logging.INFO)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def synthetic_data(hypers, args):\n", "    logging.info(\"Generating synthetic data\")\n", "    M = args.num_sources #number of data sources\n", "    N = 150 #number of samples/examples \n", "    Dm = np.array([60, 40, 20]) #number of features/variables in each data source\n", "    D = sum(Dm)\n", "    K_true = 3 #number of latent components to generate the data\n\n", "    # Implement regularized horseshoe prior over Z\n", "    Z = np.reshape(np.random.normal(0, 1, N * K_true), (N,K_true))\n", "    \n", "    #lambda Z\n", "    lmbZ0 = 0.001\n", "    lmbZ = 200 * np.ones((N,K_true))\n", "    lmbZ[50:,0] = lmbZ0\n", "    lmbZ[0:50,1] = lmbZ0; lmbZ[100:150,1] = lmbZ0\n", "    \n", "    #tau Z\n", "    tauZ = 0.01\n", "    for k in range(K_true):\n", "        Z[:,k] = Z[:,k] * lmbZ[:,k] * tauZ\n", "    \n", "    #sigmas\n", "    sigma = np.array([3, 6, 4])\n", "    logging.debug(f\"Z shape: {Z.shape}, sigma: {sigma}\")\n", "    \n", "    # Implement regularized horsesho prior over W\n", "    #lambda W\n", "    percW = 33 * np.ones((1,K_true))\n", "    pW = np.round((percW/100) * Dm)\n", "    lmbW = np.zeros((D,K_true)) * 0.01\n", "    lmbW0 = 100; d = 0\n", "    for m in range(M): \n", "        for k in range(K_true):\n", "            lmbW[np.random.choice(\n", "                    np.arange(Dm[m]), int(pW[0,m]), replace=False) + d, k] = lmbW0\n", "        d += Dm[m]\n", "    #tau W        \n", "    tauW = np.zeros((1,M))\n", "    for m in range(M):\n", "        scaleW = pW[0,m] / ((Dm[m] - pW[0,m]) * np.sqrt(N))\n", "        tauW[0,m] =  scaleW * 1/np.sqrt(sigma[m])   \n", "    #c W   \n", "    cW = np.reshape(invgamma.rvs(0.5 * hypers['slab_df'],\n", "        scale=0.5 * hypers['slab_df'], size=M*K_true),(M,K_true))\n", "    cW = hypers['slab_scale'] * np.sqrt(cW)    \n", "    W = np.random.normal(0, 1, (D,K_true))\n", "    X = np.zeros((N,D)); d = 0\n", "    for m in range(M): \n", "        lmbW_sqr = np.reshape(np.square(lmbW[d:d+Dm[m],:]), (Dm[m],K_true))\n", "        lmbW[d:d+Dm[m],:] = np.sqrt(cW[m,:] ** 2 * lmbW_sqr / \n", "                (cW[m,:] ** 2 + tauW[0,m] ** 2 * lmbW_sqr))\n", "        W[d:d+Dm[m],:] = W[d:d+Dm[m],:] * lmbW[d:d+Dm[m],:] * tauW[0,m]\n", "        \n", "        # Generate X^(m)\n", "        X[:,d:d+Dm[m]] = np.dot(Z,W[d:d+Dm[m],:].T) + \\\n", "            np.reshape(np.random.normal(0, 1/np.sqrt(sigma[m]), N*Dm[m]),(N,Dm[m])) \n", "        d += Dm[m]\n\n", "    #Save parameters\n", "    data = {'X': X, 'Z': Z, 'tauZ': tauZ, 'lmbZ': lmbZ, 'sigma': sigma,\n", "        'W': W, 'tauW': tauW, 'lmbW': lmbW, 'cW': cW, 'K_true': K_true, 'Dm': Dm}       \n", "    return data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_dataset_qmap_pd(args) -> Dict[str, Any]:\n", "    \"\"\"\n", "    Load qMAP-PD as either:\n", "      - separate ROI views (SN, Putamen, Lentiform) + clinical, when args.roi_views is True\n", "      - a single concatenated imaging view + clinical, when args.roi_views is False\n", "    \"\"\"\n", "    return qmap_pd(\n", "        data_dir=args.data_dir,\n", "        clinical_rel=args.clinical_rel,\n", "        volumes_rel=args.volumes_rel,\n", "        imaging_as_single_view=not args.roi_views,\n", "        drop_constant_clinical=True,\n", "        id_col=args.id_col,\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_data(dataset: str, data_dir: str, **kwargs):\n", "    ds = dataset.lower()\n", "    if ds in {\"qmap_pd\", \"qmap-pd\", \"qmap\"}:\n", "        return qmap_pd(data_dir, **kwargs)\n", "    elif ds in {\"synthetic\", \"toy\"}:\n", "        # optional: keep or remove\n", "        syn = synthetic_data(hypers={\"slab_df\": 1.0, \"slab_scale\": 1.0}, args=type(\"A\", (), {\"num_sources\":3})())\n", "        return {\n", "            \"X_list\": [syn[\"X\"]],\n", "            \"view_names\": [\"synthetic\"],\n", "            \"feature_names\": {\"synthetic\": [f\"f{i}\" for i in range(syn[\"X\"].shape[1])]},\n", "            \"subject_ids\": [f\"s{i}\" for i in range(syn[\"X\"].shape[0])],\n", "            \"clinical\": pd.DataFrame(index=[f\"s{i}\" for i in range(syn[\"X\"].shape[0])]),\n", "            \"Dm\": syn[\"Dm\"], \n", "            \"meta\": {\"Dm\": syn[\"Dm\"]},\n", "        }\n", "    else:\n", "        raise ValueError(f\"Unknown dataset: {dataset}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}